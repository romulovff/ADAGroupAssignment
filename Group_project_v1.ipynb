{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebeaa91c",
   "metadata": {
    "id": "ebeaa91c"
   },
   "source": [
    "# Group project\n",
    "\n",
    "By delivering this notebook, we confirm that the group project was developed by the following students.\n",
    "\n",
    "## Student 1: STUDENT NAME, STUDENT NUMBER (TO BE FILLED BY THE STUDENT)\n",
    "## Student 2: STUDENT NAME, STUDENT NUMBER (TO BE FILLED BY THE STUDENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e90bac",
   "metadata": {
    "id": "d9e90bac"
   },
   "source": [
    "The group project will focus on analysing data on flights in the US.\n",
    "\n",
    "Unless otherwise specified, the problems can be solved using either Spark or Pandas.\n",
    "\n",
    "Some useful links:\n",
    "\n",
    "* [Spark web site](https://spark.apache.org/)\n",
    "\n",
    "* [Spark MLlib main page](https://spark.apache.org/mllib/)\n",
    "* [Spark MLlib guide](https://spark.apache.org/docs/latest/ml-guide.html)\n",
    "\n",
    "* [Spark GraphX main page](https://spark.apache.org/graphx/)\n",
    "* [Spark GraphFrames main page](https://graphframes.github.io/graphframes/docs/_site/index.html)\n",
    "* [Spark GraphFrames User Guide](https://graphframes.github.io/graphframes/docs/_site/user-guide.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f57801",
   "metadata": {
    "id": "b6f57801"
   },
   "source": [
    "## Colab setup\n",
    "\n",
    "The following cell will install Spark, if the notebook is running on COLAB. Before running this cell, you should access the following link [https://drive.google.com/drive/folders/1hylIwkzcOWjYMQW2wWSVRmAN9mEyGToP?usp=sharing](https://drive.google.com/drive/folders/1hylIwkzcOWjYMQW2wWSVRmAN9mEyGToP?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae91c0",
   "metadata": {
    "id": "5fae91c0"
   },
   "outputs": [],
   "source": [
    "#Run this cell to install Spark on Colab\n",
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ : \n",
    "    !apt-get install openjdk-8-jdk-headless\n",
    "    !pip install pyspark==3.1.2\n",
    "    !wget https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.1-s_2.12/graphframes-0.8.2-spark3.1-s_2.12.jar\n",
    "    os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars graphframes-0.8.2-spark3.1-s_2.12.jar pyspark-shell'\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22fa1b",
   "metadata": {
    "id": "9b22fa1b"
   },
   "source": [
    "## Local setup\n",
    "\n",
    "For running the group project locally, you should create a directory named **data** in the directory where you have this notebook. Then, you should download to the **data** directory the files in the following link: [https://drive.google.com/drive/folders/1hylIwkzcOWjYMQW2wWSVRmAN9mEyGToP?usp=sharing](https://drive.google.com/drive/folders/1hylIwkzcOWjYMQW2wWSVRmAN9mEyGToP?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83396505",
   "metadata": {
    "id": "83396505"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aac495",
   "metadata": {
    "id": "d3aac495"
   },
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69621cc6",
   "metadata": {
    "id": "69621cc6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "print(pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5839cf",
   "metadata": {
    "id": "ee5839cf"
   },
   "source": [
    "Let's start spark session and set *log* level to ERROR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad40951",
   "metadata": {
    "id": "6ad40951"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Group project\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "if 'COLAB_GPU' in os.environ : \n",
    "    spark.sparkContext.addPyFile('graphframes-0.8.2-spark3.1-s_2.12.jar')\n",
    "elif 'DATABRICKS_RUNTIME_VERSION' in os.environ : \n",
    "    # TO BE COMPLETE\n",
    "    ;\n",
    "else:\n",
    "    spark.sparkContext.addPyFile('/usr/local/spark/jars/graphframes-0.8.1-spark3.0-s_2.12.jar')\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23071d0",
   "metadata": {
    "id": "e23071d0"
   },
   "source": [
    "## Data selection\n",
    "\n",
    "This cell controls the dataset you will be using. Note that this cell will control the path to the files, dependening on the platform you are using to run the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836342f",
   "metadata": {
    "id": "c836342f"
   },
   "outputs": [],
   "source": [
    "# Comment the following \n",
    "flightsF = \"sample.csv\"\n",
    "#flightsF = \"complete.csv\"\n",
    "#flightsF = \"data-2009.csv\"\n",
    "#flightsF = \"data-2010.csv\"\n",
    "#flightsF = \"data-2011.csv\"\n",
    "#flightsF = \"data-2012.csv\"\n",
    "#flightsF = \"data-2013.csv\"\n",
    "#flightsF = \"data-2014.csv\"\n",
    "#flightsF = \"data-2015.csv\"\n",
    "#flightsF = \"data-2016.csv\"\n",
    "#flightsF = \"data-2017.csv\"\n",
    "#flightsF = \"data-2018.csv\"\n",
    "\n",
    "if 'COLAB_GPU' in os.environ : \n",
    "    FLIGHTS_FILENAME = \"/content/drive/MyDrive/group2122/\" + flightsF\n",
    "    AIRPORTS_FILENAME = \"/content/drive/MyDrive/group2122/airports.csv\"\n",
    "    HOLIDAYS_FILENAME = \"/content/drive/MyDrive/group2122/holidays.csv\"\n",
    "elif 'DATABRICKS_RUNTIME_VERSION' in os.environ : \n",
    "    # TO BE COMPLETE\n",
    "    ;\n",
    "else:\n",
    "    FLIGHTS_FILENAME = os.path.join( \"data\", flightsF)\n",
    "    AIRPORTS_FILENAME = os.path.join( \"data\", \"airports.csv\")\n",
    "    HOLIDAYS_FILENAME = os.path.join( \"data\", \"holidays.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a44fe",
   "metadata": {
    "id": "198a44fe"
   },
   "source": [
    "## Datasets\n",
    "\n",
    "This section describes the datasets you have available for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ef634",
   "metadata": {
    "id": "514ef634"
   },
   "source": [
    "### Flights\n",
    "\n",
    "The flights dataset, generated from data available at [https://www.transtats.bts.gov/DataIndex.asp](https://www.transtats.bts.gov/DataIndex.asp), includes the following columns:\n",
    "\n",
    "* FL_DATE: date of the flight (format: yyyy-mm-dd)\n",
    "* OP_CARRIER: carrier code\n",
    "* OP_CARRIER_FL_NUM: carrier flight number\n",
    "* ORIGIN: origin airport (using IATA codes)\n",
    "* DEST: destination airport (using IATA codes)\n",
    "* CRS_DEP_TIME: scheduled local departure time (format for all times: hh:mm)\n",
    "* DEP_TIME: actual departure time\n",
    "* DEP_DELAY: departure delay, in minutes\n",
    "* TAXI_OUT: taxi out time\n",
    "* WHEELS_OFF: actual local wheel off time\n",
    "* WHEELS_ON: actual local wheel on time\n",
    "* TAXI_IN: actual local taxi in time\n",
    "* CRS_ARR_TIME: scheduled local arrival time\n",
    "* ARR_TIME: actual arrival time\n",
    "* ARR_DELAY: arrival delay, in minutes\n",
    "* CANCELLED: 1 if the flight has been cancelled; 0 otherwise\n",
    "* CANCELLATION_CODE: code of cancelation (A = carrier, B = weather, C = NAS, D = security)\n",
    "* DIVERTED: 1 if the flight has been diverted; 0 otherwise\n",
    "* CRS_ELAPSED_TIME: estimated elapsed time\n",
    "* ACTUAL_ELAPSED_TIME: actual elapsed time\n",
    "* AIR_TIME: flight time, in minutes\n",
    "* DISTANCE: flight distance, in miles\n",
    "* CARRIER_DELAY: delay due to carrier, in minutes\n",
    "* WEATHER_DELAY: delay due to weather, in minutes\n",
    "* NAS_DELAY: delay due to NAS, in minutes\n",
    "* SECURITY_DELAY: delay due to security, in minutes\n",
    "* LATE_AIRCRAFT_DELAY: delay due to late aircraft, in minutes\n",
    "\n",
    "The following data files are available:\n",
    "\n",
    "* complete.csv : complete data set, including data from 2009 to 2018\n",
    "* sample.csv : sample data set, including data from July 1 to July 15, from years 2009 to 2018\n",
    "* data-20xx.csv : data set for a particular year\n",
    "\n",
    "Load the dataset into flightsDF dataframe and register flights under view name **flights**. We are setting the schema programmatically, because inferring the schema in a very large dataframe is slow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac960a",
   "metadata": {
    "id": "a4ac960a"
   },
   "outputs": [],
   "source": [
    "flightsSchema = StructType([\n",
    "    StructField(\"FL_DATE\", DateType()),\n",
    "    StructField(\"OP_CARRIER\", StringType()),\n",
    "    StructField(\"OP_CARRIER_FL_NUM\", IntegerType()),\n",
    "    StructField(\"ORIGIN\", StringType()),\n",
    "    StructField(\"DEST\", StringType()),\n",
    "    StructField(\"CRS_DEP_TIME\", StringType()),\n",
    "    StructField(\"DEP_TIME\", StringType()),\n",
    "    StructField(\"DEP_DELAY\", IntegerType()),\n",
    "    StructField(\"TAXI_OUT\", IntegerType()),\n",
    "    StructField(\"WHEELS_OFF\", StringType()),\n",
    "    StructField(\"WHEELS_ON\", StringType()),\n",
    "    StructField(\"TAXI_IN\", IntegerType()),\n",
    "    StructField(\"CRS_ARR_TIME\", StringType()),\n",
    "    StructField(\"ARR_TIME\", StringType()),\n",
    "    StructField(\"ARR_DELAY\", IntegerType()),\n",
    "    StructField(\"CANCELLED\", IntegerType()),\n",
    "    StructField(\"CANCELLATION_CODE\", StringType()),\n",
    "    StructField(\"DIVERTED\", IntegerType()),\n",
    "    StructField(\"CRS_ELAPSED_TIME\", IntegerType()),\n",
    "    StructField(\"ACTUAL_ELAPSED_TIME\", IntegerType()),\n",
    "    StructField(\"AIR_TIME\", IntegerType()),\n",
    "    StructField(\"DISTANCE\", IntegerType()),\n",
    "    StructField(\"CARRIER_DELAY\", IntegerType()),\n",
    "    StructField(\"WEATHER_DELAY\", IntegerType()),\n",
    "    StructField(\"NAS_DELAY\", IntegerType()),\n",
    "    StructField(\"SECURITY_DELAY\", IntegerType()),\n",
    "    StructField(\"LATE_AIRCRAFT_DELAY\", IntegerType())\n",
    "    ])\n",
    "\n",
    "flightsDF = spark.read.option(\"header\", True).schema(flightsSchema).csv(FLIGHTS_FILENAME)\n",
    "\n",
    "flightsDF.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "flightsDF.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaea788",
   "metadata": {
    "id": "3aaea788"
   },
   "source": [
    "### Airports\n",
    "\n",
    "The airports dataset includes the information about US airports - soure: [https://datahub.io/core/airport-codes](https://datahub.io/core/airport-codes).\n",
    "\n",
    "This dataset includes the following columns:\n",
    "\n",
    "* ident: identifier\n",
    "* type: type of airport\n",
    "* name: name of airport\n",
    "* elevation_ft: altitude, in feets\n",
    "* continent: code of continent\n",
    "* iso_country: coide of country\n",
    "* iso_regio: code of region\n",
    "* municipality: city\n",
    "* gps_code: code of GPS\n",
    "* iata_code: IATA code of aurport\n",
    "* local_code: local code of airport\n",
    "* coordinates: coordinates of airport\n",
    "\n",
    "Load the dataset into airportDF dataframe and register airports under view name **airports**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558994b",
   "metadata": {
    "id": "d558994b"
   },
   "outputs": [],
   "source": [
    "airportsDF = spark.read.option(\"header\", True).option(\"inferSchema\",True).csv(AIRPORTS_FILENAME)\n",
    "\n",
    "airportsDF.createOrReplaceTempView(\"airports\")\n",
    "\n",
    "airportsDF.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d4c09",
   "metadata": {
    "id": "122d4c09"
   },
   "source": [
    "Exemplify how you can plot information about airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892455de",
   "metadata": {
    "id": "892455de"
   },
   "outputs": [],
   "source": [
    "airportLocDF = spark.sql(\"\"\"SELECT FLOAT(TRIM(SUBSTRING_INDEX(coordinates,',',1))) AS lon,\n",
    "                                    FLOAT(TRIM(SUBSTRING_INDEX(coordinates,',',-1))) AS lat,\n",
    "                                    elevation_ft AS val\n",
    "                        FROM airports \n",
    "                        WHERE type = 'large_airport' AND continent = 'NA' AND iso_country = 'US'\"\"\")\n",
    "\n",
    "print('Plotting airport location - using altitude for different color')\n",
    "airportLocPD = airportLocDF.toPandas()\n",
    "airportLocPD.plot(x=\"lon\",y=\"lat\",c=\"val\",s=10,cmap=\"rainbow\",kind=\"scatter\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5d9b9",
   "metadata": {
    "id": "e9c5d9b9"
   },
   "source": [
    "### Public holidays\n",
    "\n",
    "Dates of public holidays in the US.\n",
    "\n",
    "This dataset includes the following columns:\n",
    "\n",
    "* Date: date (format: yyyy-mm-dd)\n",
    "* Holiday: name of the holiday\n",
    "* WeekDay: day of week\n",
    "* Month: month (1-12)\n",
    "* Day: day (1-31)\n",
    "* Year: year (2002-2021)\n",
    "\n",
    "Load the dataset into holidaysDF dataframe and register holidays under view name **holidays**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5f8df",
   "metadata": {
    "id": "d9f5f8df"
   },
   "outputs": [],
   "source": [
    "holidaysDF = spark.read.option(\"header\", True).option(\"inferSchema\",True).csv(HOLIDAYS_FILENAME)\n",
    "\n",
    "holidaysDF.createOrReplaceTempView(\"holidays\")\n",
    "\n",
    "holidaysDF.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcbef8",
   "metadata": {
    "id": "47dcbef8"
   },
   "source": [
    "## Problem 0 [1 point]\n",
    "\n",
    "We start by executing some simple statistics to compare the execution time between Spark and Pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65575f27",
   "metadata": {
    "id": "65575f27"
   },
   "source": [
    "### Code: Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b53bb",
   "metadata": {
    "id": "782b53bb"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "flightsSchema = StructType([\n",
    "    StructField(\"FL_DATE\", DateType()),\n",
    "    StructField(\"OP_CARRIER\", StringType()),\n",
    "    StructField(\"OP_CARRIER_FL_NUM\", IntegerType()),\n",
    "    StructField(\"ORIGIN\", StringType()),\n",
    "    StructField(\"DEST\", StringType()),\n",
    "    StructField(\"CRS_DEP_TIME\", StringType()),\n",
    "    StructField(\"DEP_TIME\", StringType()),\n",
    "    StructField(\"DEP_DELAY\", IntegerType()),\n",
    "    StructField(\"TAXI_OUT\", IntegerType()),\n",
    "    StructField(\"WHEELS_OFF\", StringType()),\n",
    "    StructField(\"WHEELS_ON\", StringType()),\n",
    "    StructField(\"TAXI_IN\", IntegerType()),\n",
    "    StructField(\"CRS_ARR_TIME\", StringType()),\n",
    "    StructField(\"ARR_TIME\", StringType()),\n",
    "    StructField(\"ARR_DELAY\", IntegerType()),\n",
    "    StructField(\"CANCELLED\", IntegerType()),\n",
    "    StructField(\"CANCELLATION_CODE\", StringType()),\n",
    "    StructField(\"DIVERTED\", IntegerType()),\n",
    "    StructField(\"CRS_ELAPSED_TIME\", IntegerType()),\n",
    "    StructField(\"ACTUAL_ELAPSED_TIME\", IntegerType()),\n",
    "    StructField(\"AIR_TIME\", IntegerType()),\n",
    "    StructField(\"DISTANCE\", IntegerType()),\n",
    "    StructField(\"CARRIER_DELAY\", IntegerType()),\n",
    "    StructField(\"WEATHER_DELAY\", IntegerType()),\n",
    "    StructField(\"NAS_DELAY\", IntegerType()),\n",
    "    StructField(\"SECURITY_DELAY\", IntegerType()),\n",
    "    StructField(\"LATE_AIRCRAFT_DELAY\", IntegerType())\n",
    "    ])\n",
    "\n",
    "flightsDF = spark.read.option(\"header\", True).schema(flightsSchema).csv(FLIGHTS_FILENAME)\n",
    "\n",
    "flightsDF.createOrReplaceTempView(\"flights_new\")\n",
    "\n",
    "result = spark.sql(\"SELECT OP_CARRIER, count(*) AS num_flights FROM flights_new GROUP BY OP_CARRIER\")\n",
    "result.show()\n",
    "\n",
    "end_time = time.time()\n",
    "print( \"Runtime = \" + str(end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ed265",
   "metadata": {
    "id": "393ed265"
   },
   "source": [
    "* Execution time for sample.csv: \n",
    "* Execution time for complete.csv: \n",
    "\n",
    "Using GPU @ Colab (go to Execution time menu and change the type of execution time to include GPU):\n",
    "\n",
    "* Execution time for sample.csv: \n",
    "* Execution time for complete.csv: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0b6a7",
   "metadata": {
    "id": "13e0b6a7"
   },
   "source": [
    "### Code: Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd002811",
   "metadata": {
    "id": "bd002811"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "mySchema = {\"FL_DATE\": \"str\",\n",
    "            \"OP_CARRIER\": \"str\",\n",
    "            \"OP_CARRIER_FL_NUM\":\"Int64\",\n",
    "            \"ORIGIN\":\"str\",\n",
    "            \"DEST\":\"str\",\n",
    "            \"CRS_DEP_TIME\":\"str\",\n",
    "            \"DEP_TIME\":\"str\",\n",
    "            \"DEP_DELAY\":\"Int64\",\n",
    "            \"TAXI_OUT\":\"Int64\",\n",
    "            \"WHEELS_OFF\":\"str\",\n",
    "            \"WHEELS_ON\":\"str\",\n",
    "            \"TAXI_IN\":\"Int64\",\n",
    "            \"CRS_ARR_TIME\":\"str\",\n",
    "            \"ARR_TIME\":\"str\",\n",
    "            \"ARR_DELAY\":\"Int64\",\n",
    "            \"CANCELLED\":\"Int64\",\n",
    "            \"CANCELLATION_CODE\":\"str\",\n",
    "            \"DIVERTED\":\"Int64\",\n",
    "            \"CRS_ELAPSED_TIME\":\"Int64\",\n",
    "            \"ACTUAL_ELAPSED_TIME\":\"Int64\",\n",
    "            \"AIR_TIME\":\"Int64\",\n",
    "            \"DISTANCE\":\"Int64\",\n",
    "            \"CARRIER_DELAY\":\"Int64\",\n",
    "            \"WEATHER_DELAY\":\"Int64\",\n",
    "            \"NAS_DELAY\":\"Int64\",\n",
    "            \"SECURITY_DELAY\":\"Int64\",\n",
    "            \"LATE_AIRCRAFT_DELAY\":\"Int64\"\n",
    "           }\n",
    "\n",
    "dataframe = pd.read_csv(FLIGHTS_FILENAME,dtype=mySchema)\n",
    "result = dataframe[[\"FL_DATE\",\"OP_CARRIER\"]].groupby(\"OP_CARRIER\").count()\n",
    "print(result)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print( \"Runtime = \" + str(end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c51c285",
   "metadata": {
    "id": "5c51c285"
   },
   "source": [
    "* Execution time for sample.csv: \n",
    "* Execution time for complete.csv: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf0588a",
   "metadata": {
    "id": "7bf0588a"
   },
   "source": [
    "**Discuss the results you have obtained:**\n",
    "COMPLETE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d86190",
   "metadata": {
    "id": "37d86190"
   },
   "source": [
    "## Problem 1 [4 points]\n",
    "\n",
    "In this first problem, you should compute a set of statistics on the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46f81e",
   "metadata": {
    "id": "af46f81e"
   },
   "source": [
    "### Top-20 airports with more flights (include the name of the airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150f6af",
   "metadata": {
    "id": "4150f6af"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31863ee",
   "metadata": {
    "id": "b31863ee"
   },
   "source": [
    "### Top-20 days with more flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17444e94",
   "metadata": {
    "id": "17444e94"
   },
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b96cde",
   "metadata": {
    "id": "66b96cde"
   },
   "source": [
    "### Periods with more flights: morning (00:00-11:59, midday 12:00-17:59, evening 18:00-23:59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9f1b8",
   "metadata": {
    "id": "66e9f1b8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9807206",
   "metadata": {
    "id": "f9807206"
   },
   "source": [
    "### Top-20 airports with longer delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ce622",
   "metadata": {
    "id": "0c1ce622"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39a9e96",
   "metadata": {
    "id": "f39a9e96"
   },
   "source": [
    "### Top 10 carriers with longer delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8859452d",
   "metadata": {
    "id": "8859452d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d1a5b6",
   "metadata": {
    "id": "a4d1a5b6"
   },
   "source": [
    "### Longer delays by period: morning (00:00-11:59, midday 12:00-17:59, evening 18:00-23:59)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1669be19",
   "metadata": {
    "id": "1669be19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbb581e1",
   "metadata": {
    "id": "cbb581e1"
   },
   "source": [
    "## Problem 2 [4 points]\n",
    "\n",
    "Assume you want to create a web site to help travellers get information about flight delays. The web site would allow a user to find out information about delays for the flight she want to take. \n",
    "The information about delays should include at least 3 statistics - suggestion: the average delay in the same route of the same carrier in the last 7 days, 30 days, 365 days, similar but considering only flights in the same week day, similar but considering flights in the same week day, but excluding holidays, etc.\n",
    "\n",
    "To support this web site, it would be necessary to build one or more indices that would be used to answer the query of the user.\n",
    "\n",
    "Write the code to build these indices - for each index, print 5 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1672a83",
   "metadata": {
    "id": "d1672a83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9204ebac",
   "metadata": {
    "id": "9204ebac"
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "**Explain your code and discuss results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b0e6d",
   "metadata": {
    "id": "822b0e6d"
   },
   "source": [
    "## Problem 3 [4 points]\n",
    "\n",
    "Transform the flights data to include a class, depending on the delay - SHORT, LONG - depending on whether the departure delay was less than 10 minutes, or greater or equal to 10 minutes.\n",
    "\n",
    "Build and evaluate a classification model for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0db82",
   "metadata": {
    "id": "6ed0db82"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5c396f",
   "metadata": {
    "id": "9f5c396f"
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "**Explain your code and discuss results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53677c5",
   "metadata": {
    "id": "e53677c5"
   },
   "source": [
    "## Problem 4 [4 points]\n",
    "\n",
    "Consider we want to cluster airports depending on their properties, such as average number of flights per day, delays, cancellations, etc.\n",
    "\n",
    "Measure the quality of your clustering result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9338a0a3",
   "metadata": {
    "id": "9338a0a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "953bacbe",
   "metadata": {
    "id": "953bacbe"
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "**Explain your code and discuss results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71dae3",
   "metadata": {
    "id": "1f71dae3"
   },
   "source": [
    "## Problem 5 [3 points]\n",
    "\n",
    "We now want to find communities of airports, i.e., airports that are connected based on the flights that exist.\n",
    "\n",
    "Propose an algorithm to solve this problem and plot the communities as a graph. Run the program with and without GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523508e",
   "metadata": {
    "id": "a523508e"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc569949",
   "metadata": {
    "id": "fc569949"
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "**Explain your code and discuss results**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Group_project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
